{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94458ffe-f3af-4655-992b-d76fa77fb3e0",
   "metadata": {},
   "source": [
    "# Edresson/wav2vec2-large-100k-voxpopuli-ft-Common-Voice_plus_TTS-Dataset-russian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fe017-032d-4a70-b153-33450d40a201",
   "metadata": {},
   "source": [
    "##### https://huggingface.co/Edresson/wav2vec2-large-100k-voxpopuli-ft-Common-Voice_plus_TTS-Dataset-russian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49acfb4f-7fd0-49ae-b262-62be091f136f",
   "metadata": {},
   "source": [
    "Wav2vec2 Large 100k Vox populi настроен на русском языке с использованием Common Voice 7.0 и M-AILABS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435e59f-f5ac-4fd4-ab96-d696dad55210",
   "metadata": {},
   "source": [
    "## Подключение библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2013bb-4c51-4970-b588-84f572e59909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets.features import Audio\n",
    "\n",
    "from transformers import AutoTokenizer, Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "# Для теста WER - Word Error Rate\n",
    "# CER - Character Error Rate\n",
    "# MER - Match Error Rate\n",
    "# WIL - Word Information Lost\n",
    "from jiwer import wer, cer, mer, wil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf64c03-2cc2-4eab-8347-6142f697ae52",
   "metadata": {},
   "source": [
    "## Использование CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72adf2d4-4685-441d-a6dc-0bc34c8b2491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code is connected to CUDA. Using GPU: NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the device name\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"Code is connected to CUDA. Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc209a52-6fe8-4951-a5b9-0b6a4d1460b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все равно у меня не хватит памяти для выполнения(\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86320dfb-0ae1-4b02-8d31-ee216a1058d7",
   "metadata": {},
   "source": [
    "Не загружаем модель через CUDA, памяти не хватило\n",
    "\n",
    "`RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 3.63 GiB total capacity; 2.56 GiB already allocated; 7.12 MiB free; 2.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4adcbe-5b99-45bd-b545-17a9115c1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим датафрейм, который будет собирать данные и сохранять\n",
    "info = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb1d31-bc40-4d85-a58a-efa0e121bdc6",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ecc7518-3b39-40df-9854-d999959d06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_ID = \"ru\"\n",
    "MODEL_ID = 'Edresson/wav2vec2-large-100k-voxpopuli-ft-Common-Voice_plus_TTS-Dataset-russian'\n",
    "PATH_MODEL = '/home/redalexdad/recognition_speech/wav2vec2-large-100k-voxpopuli-ft-Common-Voice_plus_TTS-Dataset-russian'\n",
    "# Кол-во текстов для предсказания\n",
    "# ВНИМАНИЕ, НЕ СТАВЬ БОЛЬШЕ 10, ОС ЗАВИСНЕТ И ЯДРО УПАДЕТ!\n",
    "SAMPLES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ebdc03-3635-4f5a-bac8-bb08d7060601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно модель загружена\n"
     ]
    }
   ],
   "source": [
    "# Проверка наличия модели в локальном пути\n",
    "if os.path.exists(PATH_MODEL):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(PATH_MODEL)\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(PATH_MODEL).to(device)\n",
    "    print('Успешно модель загружена')\n",
    "else:\n",
    "    # Загрузка токенизатора из сети\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "    tokenizer.save_pretrained(PATH_MODEL)\n",
    "    \n",
    "    # Загрузка модели из сети\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID).to(device)\n",
    "    model.save_pretrained(PATH_MODEL)\n",
    "    \n",
    "    print(f'Успешно процессор и модель скачаны и сохранены в пути {PATH_MODEL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3633b52-78c4-4b48-90a4-3bbdfcee75e5",
   "metadata": {},
   "source": [
    "## Загрузка датасета `common_voice_11_0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe875f79-ade7-45fa-b0bc-71a28c43129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 359 ms, sys: 11.5 ms, total: 371 ms\n",
      "Wall time: 5.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_dataset_cv_11 = load_dataset(\"mozilla-foundation/common_voice_11_0\", LANG_ID, split=f\"test[:{SAMPLES}]\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8f192cf-2cb4-4cd5-aab2-2a32d4d3a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6daed0c9-27a7-4f43-82fc-f96ff631320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_ignore_regex = r\"[^A-Za-z0-9(),!?\\'\\`\\\"\\_\\n]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ede8352-1007-421c-a684-af01ea85a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_array(batch):\n",
    "    speech, _ = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler.forward(speech.squeeze(0)).numpy()\n",
    "    batch[\"sampling_rate\"] = resampler.new_freq\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower().replace(\"â€™\", \"'\")\n",
    "    \n",
    "    # Токенизация и создание маски внимания\n",
    "    tokens = tokenizer(batch[\"sentence\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    batch[\"input_values\"] = tokens[\"input_ids\"]\n",
    "    batch[\"attention_mask\"] = tokens[\"attention_mask\"]\n",
    "\n",
    "    # Явное приведение типа данных\n",
    "    batch[\"input_values\"] = batch[\"input_values\"].to(dtype=torch.float32)\n",
    "    batch[\"attention_mask\"] = batch[\"attention_mask\"].to(dtype=torch.float32)\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f261f8-ce08-4895-8d98-24f5d2c6f8be",
   "metadata": {},
   "source": [
    "### Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79ec5c04-100d-4a7f-96cc-565fb85c0f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Освобождаем памяти\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb2ccc9-784f-46ca-8651-3bcbbe7eaf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_pred(batch):\n",
    "    # Загрузка аудиофайла (первый элемент списка)\n",
    "    audio_path = batch[\"path\"][0]\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)\n",
    "    speech, _ = torchaudio.load(audio_path)\n",
    "    input_values = resampler.forward(speech.squeeze(0)).numpy()\n",
    "\n",
    "    # Токенизация и получение предсказания от модели\n",
    "    # добавляем размерность пакета\n",
    "    input_values = torch.tensor(input_values).unsqueeze(0).to(device)  \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Декодирование предсказанных токенов в текст\n",
    "    transcription = tokenizer.batch_decode(predicted_ids)[0]\n",
    "\n",
    "    return {\"predicted_text\": [transcription]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d32419d9-b988-428e-938c-60d8eaa27985",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = test_dataset_cv_11.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89536aaa-d0db-4f31-890f-7adc69a4ade7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_cv_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e15df0dd-de35-47bc-b951-b1886bdf75f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d786e7ab5b741eeaacac49965d6e543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = ds.map(map_to_pred, batched=True, batch_size=1, remove_columns=list(test_dataset_cv_11.features.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b94c04-49af-4d57-8091-53ae99ea37fd",
   "metadata": {},
   "source": [
    "### Вывод результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ffda5fd-7bed-41af-b57e-ec8f6ac8894b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 1 \n",
      "- Канонический текст: К сожалению, эти предложения не нашли отражения в тексте.\n",
      "- Предсказанный текст: сожагление это предложение на насле праженны текст\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 2 \n",
      "- Канонический текст: Если не будет возражений, я буду считать, что Ассамблея согласна с этим предложением.\n",
      "- Предсказанный текст: если не будет возражений я буду считать что ассамблеея согласна с этим предложением\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 3 \n",
      "- Канонический текст: Новошахтинск — милый город\n",
      "- Предсказанный текст: ла вашавтинска милый город\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 4 \n",
      "- Канонический текст: Мы особенно рады отметить, что число скрывающихся от правосудия лиц уменьшилось.\n",
      "- Предсказанный текст: а\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 5 \n",
      "- Канонический текст: Контроллер\n",
      "- Предсказанный текст: контраот\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 6 \n",
      "- Канонический текст: Создание устойчивых обществ требует от нас готовности на всех уровнях.\n",
      "- Предсказанный текст: создание сточи вахавшеской по запросо срусим сахаробу\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 7 \n",
      "- Канонический текст: Нет, я не вижу, почему это не может быть новая сила, если она....\n",
      "- Предсказанный текст: нетонеже к тему это не может быть нами соместаы\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 8 \n",
      "- Канонический текст: Палестинцам необходимо сначала установить мир с Израилем, а затем добиваться признания государственности.\n",
      "- Предсказанный текст: палестинцам необходимо сначало установитьс ни мир с израилем а затем добиваться признание государственности\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 9 \n",
      "- Канонический текст: Наталия\n",
      "- Предсказанный текст: виталия\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 10 \n",
      "- Канонический текст: И главное, переговори с ней.\n",
      "- Предсказанный текст: и главное переговорить с ним\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Вывод оригинальных и предсказанных текстов\n",
    "print('-' * 100)\n",
    "for i, batch in enumerate(result[\"predicted_text\"]):\n",
    "    original_texts = test_dataset_cv_11[i][\"sentence\"]\n",
    "    transcription = batch\n",
    "\n",
    "    print(f\"Пример {i + 1} \\n- Канонический текст: {original_texts}\")\n",
    "    print(f\"- Предсказанный текст: {transcription}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4986f-fb0a-44ca-a5bb-0edfb7581672",
   "metadata": {},
   "source": [
    "### Тест WER, CER, MER, WIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53d0ce14-ee19-4bc4-abb4-c2cef235c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем все к нижнему регистру\n",
    "original_texts = [ref.lower() for ref in test_dataset_cv_11[\"sentence\"]]\n",
    "transcription = [pred.lower() for pred in result[\"predicted_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9caa2d82-a604-425f-8d08-03a1f4ea1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитаем WER\n",
    "wer_score = wer(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3305419a-6dd5-4ec8-a1a8-9e6ca56db128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 69.62%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word Error Rate (WER): {wer_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76e54d9f-ff3a-4d54-a5cd-e6a4547c3e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и CER\n",
    "cer_score = cer(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf51a70e-79a5-4475-b2e0-445782353cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate (CER): 37.71%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Character Error Rate (CER): {cer_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20aea7a5-56b5-4e48-820d-ff340177a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MER\n",
    "mer_score = mer(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eeb5ef0-c865-460b-92ba-b0f5ab1d6ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Error Rate (MER): 68.75%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Match Error Rate (MER): {mer_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "344aa4df-5731-42a5-985c-e02b0df15bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIL\n",
    "wil_score = wil(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26e820a1-baa2-49b2-9db3-e368688de06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Information Lost (WIL): 87.03%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word Information Lost (WIL): {wil_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82de810f-9b5f-4236-829a-d60b7ca1adef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13309/3376670737.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  info = info.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>DATASET</th>\n",
       "      <th>ORIGINAL TEXT</th>\n",
       "      <th>PREDICTION TEXT</th>\n",
       "      <th>WER</th>\n",
       "      <th>CER</th>\n",
       "      <th>MER</th>\n",
       "      <th>WIL</th>\n",
       "      <th>SAMPLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...</td>\n",
       "      <td>common_voice_11_0</td>\n",
       "      <td>[к сожалению, эти предложения не нашли отражен...</td>\n",
       "      <td>[сожагление это предложение на насле праженны ...</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.377111</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.870305</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               MODEL            DATASET  \\\n",
       "0  Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...  common_voice_11_0   \n",
       "\n",
       "                                       ORIGINAL TEXT  \\\n",
       "0  [к сожалению, эти предложения не нашли отражен...   \n",
       "\n",
       "                                     PREDICTION TEXT       WER       CER  \\\n",
       "0  [сожагление это предложение на насле праженны ...  0.696203  0.377111   \n",
       "\n",
       "      MER       WIL  SAMPLES  \n",
       "0  0.6875  0.870305       10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создание датафрейма\n",
    "info = info.append({\n",
    "    'MODEL': MODEL_ID,\n",
    "    'DATASET': test_dataset_cv_11.info.dataset_name,\n",
    "    'ORIGINAL TEXT': original_texts,\n",
    "    'PREDICTION TEXT': transcription,\n",
    "    'WER': wer_score,\n",
    "    'CER': cer_score,\n",
    "    'MER': mer_score,\n",
    "    'WIL': wil_score,\n",
    "    'SAMPLES': SAMPLES\n",
    "}, ignore_index=True)\n",
    "display(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670210c7-7c82-41ea-bf5d-7cd9d82b130c",
   "metadata": {},
   "source": [
    "## Загрузка датасета `common_voice_12_0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f40bd149-af8e-41db-8049-564f840a8975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 336 ms, sys: 8.01 ms, total: 344 ms\n",
      "Wall time: 5.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_dataset_cv_12 = load_dataset(\"mozilla-foundation/common_voice_12_0\", LANG_ID, split=f\"test[:{SAMPLES}]\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55448fd0-6810-4b6b-a168-ba0149f27cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edd1e36b-2ca2-4425-8291-d92fda9d928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_ignore_regex = r\"[^A-Za-z0-9(),!?\\'\\`\\\"\\_\\n]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc36485d-007d-419a-88aa-72c17ded567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_array(batch):\n",
    "    speech, _ = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler.forward(speech.squeeze(0)).numpy()\n",
    "    batch[\"sampling_rate\"] = resampler.new_freq\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower().replace(\"â€™\", \"'\")\n",
    "    \n",
    "    # Токенизация и создание маски внимания\n",
    "    tokens = tokenizer(batch[\"sentence\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    batch[\"input_values\"] = tokens[\"input_ids\"]\n",
    "    batch[\"attention_mask\"] = tokens[\"attention_mask\"]\n",
    "\n",
    "    # Явное приведение типа данных\n",
    "    batch[\"input_values\"] = batch[\"input_values\"].to(dtype=torch.float32)\n",
    "    batch[\"attention_mask\"] = batch[\"attention_mask\"].to(dtype=torch.float32)\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f7640-54e9-4a1e-9b7f-8d555607813c",
   "metadata": {},
   "source": [
    "### Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17541dd0-7baa-44d8-8114-5d33ce90fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Освобождаем памяти\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dead4d9a-55b5-47dd-8844-c774f51f7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_pred(batch):\n",
    "    # Загрузка аудиофайла (первый элемент списка)\n",
    "    audio_path = batch[\"path\"][0]\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)\n",
    "    speech, _ = torchaudio.load(audio_path)\n",
    "    input_values = resampler.forward(speech.squeeze(0)).numpy()\n",
    "\n",
    "    # Токенизация и получение предсказания от модели\n",
    "    # добавляем размерность пакета\n",
    "    input_values = torch.tensor(input_values).unsqueeze(0).to(device)  \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Декодирование предсказанных токенов в текст\n",
    "    transcription = tokenizer.batch_decode(predicted_ids)[0]\n",
    "\n",
    "    return {\"predicted_text\": [transcription]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08da9ace-2a16-4fa6-a671-c7e571cd55c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0890e8338a40909bf75282830193d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "ds = test_dataset_cv_12.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb501ef8-99a5-4b5b-9cc1-8bb328e89344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_cv_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0b85f06-d83d-4f32-b04d-9aa4a4ed9df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e38f6546d240678fe513d082499df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = ds.map(map_to_pred, batched=True, batch_size=1, remove_columns=list(test_dataset_cv_12.features.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1dff96-8dcf-4a2c-8837-ad645d60c24b",
   "metadata": {},
   "source": [
    "### Вывод результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd2404cc-12ee-4589-8f1e-de129ead365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 1 \n",
      "- Канонический текст: К сожалению, эти предложения не нашли отражения в тексте.\n",
      "- Предсказанный текст: сожагление это предложение на насле праженны текст\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 2 \n",
      "- Канонический текст: Толпа озвереет, будет тереться, ощетинит ножки стоглавая вошь.\n",
      "- Предсказанный текст: талпа звереет будет целяться пощительно множто стоглавый вож\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 3 \n",
      "- Канонический текст: А жизнь ее была не весела.\n",
      "- Предсказанный текст: а жизни е была невесева\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 4 \n",
      "- Канонический текст: Если не будет возражений, я буду считать, что Ассамблея согласна с этим предложением.\n",
      "- Предсказанный текст: если не будет возражений я буду считать что ассамблеея согласна с этим предложением\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 5 \n",
      "- Канонический текст: Да ты зачем собственно приехал?\n",
      "- Предсказанный текст: да ты зачем собственно поехал\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 6 \n",
      "- Канонический текст: Мы особенно рады отметить, что число скрывающихся от правосудия лиц уменьшилось.\n",
      "- Предсказанный текст: а\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 7 \n",
      "- Канонический текст: Контроллер\n",
      "- Предсказанный текст: контраот\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 8 \n",
      "- Канонический текст: Пугачев весело со мною поздоровался и велел мне садиться с ним в кибитку.\n",
      "- Предсказанный текст: бугачеш десего асеммлее поздоаровался имее насадительстно тибепком\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 9 \n",
      "- Канонический текст: Неожиданно катастрофа приобрела глобальные масштабы.\n",
      "- Предсказанный текст: невежиданная катастрофа прявлила глобальние маштабы\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 10 \n",
      "- Канонический текст: Нет, я не вижу, почему это не может быть новая сила, если она....\n",
      "- Предсказанный текст: нетонеже к тему это не может быть нами соместаы\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Вывод оригинальных и предсказанных текстов\n",
    "print('-' * 100)\n",
    "for i, batch in enumerate(result[\"predicted_text\"]):\n",
    "    original_texts = test_dataset_cv_12[i][\"sentence\"]\n",
    "    transcription = batch\n",
    "\n",
    "    print(f\"Пример {i + 1} \\n- Канонический текст: {original_texts}\")\n",
    "    print(f\"- Предсказанный текст: {transcription}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f75eb-b505-4b72-afc2-df861d1b64b1",
   "metadata": {},
   "source": [
    "### Тест WER, CER, MER, WIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "022046f6-86d5-449f-a671-6c4d4a7596ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем все к нижнему регистру\n",
    "original_texts = [ref.lower() for ref in test_dataset_cv_12[\"sentence\"]]\n",
    "transcription = [pred.lower() for pred in result[\"predicted_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ca5d483-b31c-4213-8bf8-e18082091d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитаем WER\n",
    "wer_score = wer(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dec1e7f-abf4-4509-8744-e631380db02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 75.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word Error Rate (WER): {wer_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0149c8f8-f2af-40e9-bd04-9af3adc0423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и CER\n",
    "cer_score = cer(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7115930d-f7c1-47cd-9c08-8afc4e95cb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate (CER): 38.82%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Character Error Rate (CER): {cer_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a62ca83c-ae56-4656-9446-7d69ef3bc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MER\n",
    "mer_score = mer(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd646f9c-0daf-4625-b7d0-10ad5b54247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Error Rate (MER): 75.00%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Match Error Rate (MER): {mer_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c594a3c-b455-4e26-800e-8a1703deb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIL\n",
    "wil_score = wil(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44be0e4c-eb75-4218-bf76-f0f4aaf2ad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Information Lost (WIL): 91.39%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word Information Lost (WIL): {wil_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9799887-1d2c-4783-b4da-2b5078c2d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13309/569941310.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  info = info.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>DATASET</th>\n",
       "      <th>ORIGINAL TEXT</th>\n",
       "      <th>PREDICTION TEXT</th>\n",
       "      <th>WER</th>\n",
       "      <th>CER</th>\n",
       "      <th>MER</th>\n",
       "      <th>WIL</th>\n",
       "      <th>SAMPLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...</td>\n",
       "      <td>common_voice_11_0</td>\n",
       "      <td>[к сожалению, эти предложения не нашли отражен...</td>\n",
       "      <td>[сожагление это предложение на насле праженны ...</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.377111</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.870305</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...</td>\n",
       "      <td>common_voice_12_0</td>\n",
       "      <td>[к сожалению, эти предложения не нашли отражен...</td>\n",
       "      <td>[сожагление это предложение на насле праженны ...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.388170</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.913934</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               MODEL            DATASET  \\\n",
       "0  Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...  common_voice_11_0   \n",
       "1  Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...  common_voice_12_0   \n",
       "\n",
       "                                       ORIGINAL TEXT  \\\n",
       "0  [к сожалению, эти предложения не нашли отражен...   \n",
       "1  [к сожалению, эти предложения не нашли отражен...   \n",
       "\n",
       "                                     PREDICTION TEXT       WER       CER  \\\n",
       "0  [сожагление это предложение на насле праженны ...  0.696203  0.377111   \n",
       "1  [сожагление это предложение на насле праженны ...  0.750000  0.388170   \n",
       "\n",
       "      MER       WIL  SAMPLES  \n",
       "0  0.6875  0.870305       10  \n",
       "1  0.7500  0.913934       10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создание датафрейма\n",
    "info = info.append({\n",
    "    'MODEL': MODEL_ID,\n",
    "    'DATASET': test_dataset_cv_12.info.dataset_name,\n",
    "    'ORIGINAL TEXT': original_texts,\n",
    "    'PREDICTION TEXT': transcription,\n",
    "    'WER': wer_score,\n",
    "    'CER': cer_score,\n",
    "    'MER': mer_score,\n",
    "    'WIL': wil_score,\n",
    "    'SAMPLES': SAMPLES\n",
    "}, ignore_index=True)\n",
    "display(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b1bc8e-ded3-4fcc-9531-1319a69f3364",
   "metadata": {},
   "source": [
    "## Загрузка датасета `common_voice_14_0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea2e8665-e417-4487-b398-f23dd9d2c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 289 ms, sys: 12.1 ms, total: 301 ms\n",
      "Wall time: 4.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_dataset_cv_14 = load_dataset(\"mozilla-foundation/common_voice_14_0\", LANG_ID, split=f\"test[:{SAMPLES}]\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ac1fe09-a83f-4dde-a605-fa4a59906a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ce0389a-e6a4-4bcf-a145-5f106a71c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_ignore_regex = r\"[^A-Za-z0-9(),!?\\'\\`\\\"\\_\\n]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "354d772e-449e-425b-b1d4-245cf880fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_array(batch):\n",
    "    speech, _ = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler.forward(speech.squeeze(0)).numpy()\n",
    "    batch[\"sampling_rate\"] = resampler.new_freq\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower().replace(\"â€™\", \"'\")\n",
    "    \n",
    "    # Токенизация и создание маски внимания\n",
    "    tokens = tokenizer(batch[\"sentence\"], return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    batch[\"input_values\"] = tokens[\"input_ids\"]\n",
    "    batch[\"attention_mask\"] = tokens[\"attention_mask\"]\n",
    "\n",
    "    # Явное приведение типа данных\n",
    "    batch[\"input_values\"] = batch[\"input_values\"].to(dtype=torch.float32)\n",
    "    batch[\"attention_mask\"] = batch[\"attention_mask\"].to(dtype=torch.float32)\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b3f83-3502-43c3-b6a0-919b81e31196",
   "metadata": {},
   "source": [
    "### Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ff62fb0-cb7e-40a3-b36c-38459d378d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Освобождаем памяти\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "807bdcfc-02d4-499d-a410-757a28f2513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_pred(batch):\n",
    "    # Загрузка аудиофайла (первый элемент списка)\n",
    "    audio_path = batch[\"path\"][0]\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)\n",
    "    speech, _ = torchaudio.load(audio_path)\n",
    "    input_values = resampler.forward(speech.squeeze(0)).numpy()\n",
    "\n",
    "    # Токенизация и получение предсказания от модели\n",
    "    # добавляем размерность пакета\n",
    "    input_values = torch.tensor(input_values).unsqueeze(0).to(device)  \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Декодирование предсказанных токенов в текст\n",
    "    transcription = tokenizer.batch_decode(predicted_ids)[0]\n",
    "\n",
    "    return {\"predicted_text\": [transcription]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "665540db-67f5-4fcd-9a2a-2299dfd235d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2687655fd5174925bf93bf54a0db088e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = test_dataset_cv_14.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b47fe2ef-80a6-41d1-9b0e-0379a4e91523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'variant'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_cv_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6d2802f-fe0a-4716-b175-9de159c4a6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a927eee8559247e6b4b2319247f86f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = ds.map(map_to_pred, batched=True, batch_size=1, remove_columns=list(test_dataset_cv_14.features.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a69fb-0d02-495d-824d-697d3bd3e73d",
   "metadata": {},
   "source": [
    "### Вывод результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb1c898f-a2b9-4514-9204-bb18a660da64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 1 \n",
      "- Канонический текст: К сожалению, эти предложения не нашли отражения в тексте.\n",
      "- Предсказанный текст: сожагление это предложение на насле праженны текст\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 2 \n",
      "- Канонический текст: Толпа озвереет, будет тереться, ощетинит ножки стоглавая вошь.\n",
      "- Предсказанный текст: талпа звереет будет целяться пощительно множто стоглавый вож\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 3 \n",
      "- Канонический текст: Если не будет возражений, я буду считать, что Ассамблея согласна с этим предложением.\n",
      "- Предсказанный текст: если не будет возражений я буду считать что ассамблеея согласна с этим предложением\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 4 \n",
      "- Канонический текст: Да ты зачем собственно приехал?\n",
      "- Предсказанный текст: да ты зачем собственно поехал\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 5 \n",
      "- Канонический текст: Мы особенно рады отметить, что число скрывающихся от правосудия лиц уменьшилось.\n",
      "- Предсказанный текст: а\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 6 \n",
      "- Канонический текст: Контроллер\n",
      "- Предсказанный текст: контраот\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 7 \n",
      "- Канонический текст: Неожиданно катастрофа приобрела глобальные масштабы.\n",
      "- Предсказанный текст: невежиданная катастрофа прявлила глобальние маштабы\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 8 \n",
      "- Канонический текст: Нет, я не вижу, почему это не может быть новая сила, если она....\n",
      "- Предсказанный текст: нетонеже к тему это не может быть нами соместаы\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 9 \n",
      "- Канонический текст: Палестинцам необходимо сначала установить мир с Израилем, а затем добиваться признания государственности.\n",
      "- Предсказанный текст: палестинцам необходимо сначало установитьс ни мир с израилем а затем добиваться признание государственности\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Пример 10 \n",
      "- Канонический текст: Тысячи людей пропали без вести.\n",
      "- Предсказанный текст: ты с солидарни подбердете\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Вывод оригинальных и предсказанных текстов\n",
    "print('-' * 100)\n",
    "for i, batch in enumerate(result[\"predicted_text\"]):\n",
    "    original_texts = test_dataset_cv_14[i][\"sentence\"]\n",
    "    transcription = batch\n",
    "\n",
    "    print(f\"Пример {i + 1} \\n- Канонический текст: {original_texts}\")\n",
    "    print(f\"- Предсказанный текст: {transcription}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dba38c-cf73-4000-a476-1368cc4f2a23",
   "metadata": {},
   "source": [
    "### Тест WER, CER, MER, WIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df758e4b-7223-4179-89d3-39c31b3feb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведем все к нижнему регистру\n",
    "original_texts = [ref.lower() for ref in test_dataset_cv_14[\"sentence\"]]\n",
    "transcription = [pred.lower() for pred in result[\"predicted_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40d9ba3f-457e-4a76-a774-472cc5ba3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитаем WER\n",
    "wer_score = wer(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb6c7042-b57b-4663-9251-26698ff369bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate (WER): 69.51%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word Error Rate (WER): {wer_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb21e18a-cca4-4dc3-a1d2-63fa9b85f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и CER\n",
    "cer_score = cer(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "573168d2-776f-4c61-8ddc-dd206d6ec679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character Error Rate (CER): 35.12%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Character Error Rate (CER): {cer_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9f09d43a-a9a7-497c-941d-c331b76cb92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MER\n",
    "mer_score = mer(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce2be910-4953-4c1e-b7d7-b332e763d65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Error Rate (MER): 68.67%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Match Error Rate (MER): {mer_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4dd2e7d-a40b-4dbe-ab62-416d17c949ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIL\n",
    "wil_score = wil(original_texts, transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f2211d7b-11b4-4821-9b04-80d7deb1a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Information Lost (WIL): 87.51%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Word Information Lost (WIL): {wil_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ded1323-a8a3-47fd-af5e-8a0e86e95d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13309/3254145418.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  info = info.append({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>DATASET</th>\n",
       "      <th>ORIGINAL TEXT</th>\n",
       "      <th>PREDICTION TEXT</th>\n",
       "      <th>WER</th>\n",
       "      <th>CER</th>\n",
       "      <th>MER</th>\n",
       "      <th>WIL</th>\n",
       "      <th>SAMPLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...</td>\n",
       "      <td>common_voice_11_0</td>\n",
       "      <td>[к сожалению, эти предложения не нашли отражен...</td>\n",
       "      <td>[сожагление это предложение на насле праженны ...</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.377111</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.870305</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...</td>\n",
       "      <td>common_voice_12_0</td>\n",
       "      <td>[к сожалению, эти предложения не нашли отражен...</td>\n",
       "      <td>[сожагление это предложение на насле праженны ...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.388170</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.913934</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...</td>\n",
       "      <td>common_voice_14_0</td>\n",
       "      <td>[к сожалению, эти предложения не нашли отражен...</td>\n",
       "      <td>[сожагление это предложение на насле праженны ...</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.351211</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.875092</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               MODEL            DATASET  \\\n",
       "0  Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...  common_voice_11_0   \n",
       "1  Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...  common_voice_12_0   \n",
       "2  Edresson/wav2vec2-large-100k-voxpopuli-ft-Comm...  common_voice_14_0   \n",
       "\n",
       "                                       ORIGINAL TEXT  \\\n",
       "0  [к сожалению, эти предложения не нашли отражен...   \n",
       "1  [к сожалению, эти предложения не нашли отражен...   \n",
       "2  [к сожалению, эти предложения не нашли отражен...   \n",
       "\n",
       "                                     PREDICTION TEXT       WER       CER  \\\n",
       "0  [сожагление это предложение на насле праженны ...  0.696203  0.377111   \n",
       "1  [сожагление это предложение на насле праженны ...  0.750000  0.388170   \n",
       "2  [сожагление это предложение на насле праженны ...  0.695122  0.351211   \n",
       "\n",
       "        MER       WIL  SAMPLES  \n",
       "0  0.687500  0.870305       10  \n",
       "1  0.750000  0.913934       10  \n",
       "2  0.686747  0.875092       10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создание датафрейма\n",
    "info = info.append({\n",
    "    'MODEL': MODEL_ID,\n",
    "    'DATASET': test_dataset_cv_14.info.dataset_name,\n",
    "    'ORIGINAL TEXT': original_texts,\n",
    "    'PREDICTION TEXT': transcription,\n",
    "    'WER': wer_score,\n",
    "    'CER': cer_score,\n",
    "    'MER': mer_score,\n",
    "    'WIL': wil_score,\n",
    "    'SAMPLES': SAMPLES\n",
    "}, ignore_index=True)\n",
    "display(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "781e0e1c-b005-4ad5-a39f-92147dc40ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "info.to_csv('wav2vec2-large-100k-voxpopuli-ft-Common-Voice_plus_TTS-Dataset-russian.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
