{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b6f98d-2f2a-44a1-9ec2-8d54a18ec872",
   "metadata": {},
   "source": [
    "# wav2vec2-xls-r-1b-russian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b50d43-1134-453f-b2a4-8e924942f9f8",
   "metadata": {},
   "source": [
    "##### https://huggingface.co/jonatasgrosman/wav2vec2-xls-r-1b-russian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b311b0-5873-477d-ad79-31496e88877a",
   "metadata": {},
   "source": [
    "Точно настроил `facebook/wav2vec2-xls-r1b` на русском языке, используя разделители `train` и `validation` в `Common Voice 8.0`, `Golos` и многоязычном `TEDx`. \n",
    "\n",
    "**При использовании этой модели убедитесь, что при вводе речи используется частота дискретизации 16 кГц.**\n",
    "\n",
    "Эта модель была точно настроена с помощью инструмента `HuggingSound` и благодаря графическому процессору, щедро предоставленному `OVHcloud` :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51b06db-c197-468f-a294-25fcaf98d5d2",
   "metadata": {},
   "source": [
    "## Подключение библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a362a047-dcbc-408b-86a0-8d028c788143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 11:43:20.818099: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 11:43:20.818131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 11:43:20.820352: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 11:43:20.830833: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 11:43:21.819287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets.features import Audio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import pandas as pd\n",
    "from huggingsound import SpeechRecognitionModel\n",
    "\n",
    "# Для теста WER - Word Error Rate\n",
    "# CER - Character Error Rate\n",
    "# MER - Match Error Rate\n",
    "# WIL - Word Information Lost\n",
    "from jiwer import wer, cer, mer, wil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cc9b22-4d89-4ccc-8454-1cfd8def7827",
   "metadata": {},
   "source": [
    "## Использование CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68952fa1-6e44-45aa-b196-0ecb138dfe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code is connected to CUDA. Using GPU: NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the device name\n",
    "    device = torch.cuda.current_device()\n",
    "    print(f\"Code is connected to CUDA. Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed88297-ef56-45cd-8523-30b09bb91709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все равно у меня не хватит памяти для выполнения(\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68181071-8e84-45d8-979c-405b070b29d2",
   "metadata": {},
   "source": [
    "Не загружаем модель через CUDA, памяти не хватило\n",
    "\n",
    "`RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 3.63 GiB total capacity; 2.56 GiB already allocated; 7.12 MiB free; 2.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59a81af0-97c3-47f5-a680-28ec7ca0ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим датафрейм, который будет собирать данные и сохранять\n",
    "info = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad22c80-b790-4c5a-8739-c8a9fd54da31",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96b19a-110d-40e2-9539-8d9646863889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/11/2024 11:44:23 - INFO - huggingsound.speech_recognition.model - Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e51acf12c7476bb21b35837a9a8747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafe809ee67645378d3a3384d7ebc0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Не загружаем, ядро зависает\n",
    "# model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-xls-r-1b-russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed12a390-2c1a-4324-a46e-ad4d1c1d04e6",
   "metadata": {},
   "source": [
    "## Небольшая проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "446b12bb-b744-4f7a-a8e1-4936bc3a510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = '/home/redalexdad/Документы/GitHub/SpeechTraining/test/voice/'\n",
    "\n",
    "audio_data = [audio_paths+\"000000_RUSLAN.wav\", audio_paths+\"000001_RUSLAN.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21acfea5-6974-4afd-bdb4-4fafd28eae5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Wav2Vec2ForCTC' object has no attribute 'transcribe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transcriptions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m(audio_paths)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/nn/modules/module.py:1177\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1177\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Wav2Vec2ForCTC' object has no attribute 'transcribe'"
     ]
    }
   ],
   "source": [
    "transcriptions = model.transcribe(audio_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31864b-a9e5-4071-95bd-14b340b8a31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0b08c-ba49-44f9-a76b-54e8822afb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43898e18-8632-4743-aefa-cecf1fab81d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756a0f6-a601-4a7f-bd7f-ee21b771105a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddea120-9927-47ea-9704-fe45beaeafd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
