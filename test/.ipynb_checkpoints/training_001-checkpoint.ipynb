{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc972fc-b185-41cd-a161-85f44d06b637",
   "metadata": {},
   "source": [
    "# Подключение библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d8703f-8b10-4734-9565-efb5876d2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d287cc5-2190-41ab-b9b1-8b7c0a1abda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio.transforms import Resample\n",
    "from torch.nn import CTCLoss\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3d5aff-f785-4c97-a5dc-d4287fe67eb5",
   "metadata": {},
   "source": [
    "## Загрузка датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f337058d-710e-40b1-8aad-7dcbac28981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка, существует ли уже сохраненный датасет\n",
    "if os.path.exists(saved_dataset_path):\n",
    "    # Загружаем сохраненный датасет, если он уже существует\n",
    "    cv_11_train = load_from_disk('/home/redalexdad/recognition_speech/common_voice_11/train/')\n",
    "    cv_11_test = load_from_disk('/home/redalexdad/recognition_speech/common_voice_11/test/')\n",
    "else:\n",
    "    # Иначе, скачиваем и сохраняем датасет\n",
    "    cv_11_train = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"ru\", split=\"train\")\n",
    "    cv_11_train.save_to_disk('/home/redalexdad/recognition_speech')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02264e6d-86ba-480b-838f-a19f113b64d6",
   "metadata": {},
   "source": [
    "## Содержимое датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30ad6c72-7bdb-47f8-8d2d-97612dec5970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    num_rows: 22862\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_11_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d7702c6-c484-4728-90a0-71f00ab9a0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    num_rows: 9630\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_11_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a888fbea-6d9c-46c0-b8a5-89f2ae0b2dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': '918b5e9edfb0aed8d7a73f938e07749e53fdda9babf808efe059e1ff3843b15b6e2e979fd619296e611965601e8219dc9f17de9dd480a08d8141942748e6f0ab',\n",
       " 'path': '/home/redalexdad/.cache/huggingface/datasets/downloads/extracted/d814cc3a56a5df3b5ccfa17b831afd6938306b9d17da77b602bb4b95387084b6/ru_train_0/common_voice_ru_26426765.mp3',\n",
       " 'audio': {'path': 'common_voice_ru_26426765.mp3',\n",
       "  'array': array([-1.06581410e-14,  8.34887715e-14,  8.08242362e-14, ...,\n",
       "         -2.88323849e-06,  1.16737738e-07,  9.74517661e-07]),\n",
       "  'sampling_rate': 48000},\n",
       " 'sentence': 'Демократия неумолимо продвигается по Африке, и «арабская весна» была ее кульминацией.',\n",
       " 'up_votes': 2,\n",
       " 'down_votes': 1,\n",
       " 'age': '',\n",
       " 'gender': '',\n",
       " 'accent': '',\n",
       " 'locale': 'ru',\n",
       " 'segment': ''}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_11_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93dde6c-427a-4d19-91ff-2a5efcd0f0e7",
   "metadata": {},
   "source": [
    "## Создание класса датасета и обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01855c5d-e125-447d-8dca-569305ffd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание класса датасета\n",
    "class VoiceDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.resampler = Resample(orig_freq=48_000, new_freq=16_000)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.dataset[idx][\"path\"]\n",
    "        waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n",
    "        waveform = self.resampler(waveform)\n",
    "        transcription = self.dataset[idx][\"sentence\"]\n",
    "        return waveform, transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90aed2d8-5e22-4d05-90a8-e5989061bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация датасета и загрузчика данных\n",
    "voice_dataset = VoiceDataset(cv_11_train)\n",
    "dataloader = DataLoader(voice_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11acee84-44be-4c56-aa0d-1093f3aaaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример определения простой модели для голосового распознавания\n",
    "class SimpleSpeechRecognitionModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleSpeechRecognitionModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a3fc7a6-480b-4a28-96e5-e6d73a03f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указание количества классов\n",
    "num_classes = 10  # Замените на фактическое количество классов в вашем датасете\n",
    "\n",
    "# Инициализация модели\n",
    "model = SimpleSpeechRecognitionModel(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b0119a9-6730-4ca5-a07b-bfb9ce43c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение функции потерь и оптимизатора\n",
    "criterion = CTCLoss(blank=0)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e7456db-d841-407a-b44e-ea9e57f13bc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 144, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 144, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [1, 43008] at entry 0 and [1, 77184] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (waveform, transcription) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(waveform)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 144, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 144, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [1, 43008] at entry 0 and [1, 77184] at entry 1\n"
     ]
    }
   ],
   "source": [
    "# Пример обучения модели на нескольких эпохах\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (waveform, transcription) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(waveform)\n",
    "        # Преобразование текстов в тензоры для расчета функции потерь CTC\n",
    "        target = torch.IntTensor([ord(char) for char in transcription])\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Эпоха {epoch+1}/{num_epochs}, Шаг {batch_idx}, Потеря: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2152b1-955b-40e5-8f6a-b755bd2a0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение обученной модели\n",
    "torch.save(model.state_dict(), \"my_model_001.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78233a-2a18-4008-bd6e-c744f756fa90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
