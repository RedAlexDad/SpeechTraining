{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d287cc5-2190-41ab-b9b1-8b7c0a1abda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio.transforms import Resample\n",
    "from datasets import load_dataset\n",
    "from torch.nn import CTCLoss\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f337058d-710e-40b1-8aad-7dcbac28981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for mozilla-foundation/common_voice_11_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_11_0\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Скачиваем датасет с русскими данными \n",
    "# https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0\n",
    "cv_11_train = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"ru\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01855c5d-e125-447d-8dca-569305ffd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание класса датасета\n",
    "class VoiceDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.resampler = Resample(orig_freq=48_000, new_freq=16_000)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = self.dataset[idx][\"path\"]\n",
    "        waveform, sample_rate = torchaudio.load(audio_path, normalize=True)\n",
    "        waveform = self.resampler(waveform)\n",
    "        transcription = self.dataset[idx][\"sentence\"]\n",
    "        return waveform, transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90aed2d8-5e22-4d05-90a8-e5989061bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация датасета и загрузчика данных\n",
    "voice_dataset = VoiceDataset(cv_11_train)\n",
    "dataloader = DataLoader(voice_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11acee84-44be-4c56-aa0d-1093f3aaaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример определения простой модели для голосового распознавания\n",
    "class SimpleSpeechRecognitionModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleSpeechRecognitionModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a3fc7a6-480b-4a28-96e5-e6d73a03f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указание количества классов\n",
    "num_classes = 10  # Замените на фактическое количество классов в вашем датасете\n",
    "\n",
    "# Инициализация модели\n",
    "model = SimpleSpeechRecognitionModel(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b0119a9-6730-4ca5-a07b-bfb9ce43c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение функции потерь и оптимизатора\n",
    "criterion = CTCLoss(blank=0)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e7456db-d841-407a-b44e-ea9e57f13bc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Caught ImportError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_300860/1671197508.py\", line 11, in __getitem__\n    audio_path = self.dataset[idx][\"path\"]\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 2810, in __getitem__\n    return self._getitem(key)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 2795, in _getitem\n    formatted_output = format_table(\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/formatting/formatting.py\", line 629, in format_table\n    return formatter(pa_table, query_type=query_type)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/formatting/formatting.py\", line 396, in __call__\n    return self.format_row(pa_table)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/formatting/formatting.py\", line 437, in format_row\n    row = self.python_features_decoder.decode_row(row)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/formatting/formatting.py\", line 215, in decode_row\n    return self.features.decode_example(row) if self.features else row\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/features/features.py\", line 1939, in decode_example\n    return {\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/features/features.py\", line 1940, in <dictcomp>\n    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/features/features.py\", line 1340, in decode_nested_example\n    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/features/audio.py\", line 191, in decode_example\n    array = librosa.to_mono(array)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/lazy_loader/__init__.py\", line 78, in __getattr__\n    attr = getattr(submod, name)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/lazy_loader/__init__.py\", line 77, in __getattr__\n    submod = importlib.import_module(submod_path)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/librosa/core/audio.py\", line 17, in <module>\n    from numba import jit, stencil, guvectorize\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/numba/__init__.py\", line 56, in <module>\n    _ensure_critical_deps()\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/numba/__init__.py\", line 40, in _ensure_critical_deps\n    raise ImportError(msg)\nImportError: Numba needs NumPy 1.22 or greater. Got NumPy 1.20.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (waveform, transcription) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(waveform)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mImportError\u001b[0m: Caught ImportError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_300860/1671197508.py\", line 11, in __getitem__\n    audio_path = self.dataset[idx][\"path\"]\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 2810, in __getitem__\n    return self._getitem(key)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 2795, in _getitem\n    formatted_output = format_table(\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/formatting/formatting.py\", line 629, in format_table\n    return formatter(pa_table, query_type=query_type)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/formatting/formatting.py\", line 396, in __call__\n    return self.format_row(pa_table)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/formatting/formatting.py\", line 437, in format_row\n    row = self.python_features_decoder.decode_row(row)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/formatting/formatting.py\", line 215, in decode_row\n    return self.features.decode_example(row) if self.features else row\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/features/features.py\", line 1939, in decode_example\n    return {\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/features/features.py\", line 1940, in <dictcomp>\n    column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/features/features.py\", line 1340, in decode_nested_example\n    return schema.decode_example(obj, token_per_repo_id=token_per_repo_id)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/datasets/features/audio.py\", line 191, in decode_example\n    array = librosa.to_mono(array)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/lazy_loader/__init__.py\", line 78, in __getattr__\n    attr = getattr(submod, name)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/lazy_loader/__init__.py\", line 77, in __getattr__\n    submod = importlib.import_module(submod_path)\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/librosa/core/audio.py\", line 17, in <module>\n    from numba import jit, stencil, guvectorize\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/numba/__init__.py\", line 56, in <module>\n    _ensure_critical_deps()\n  File \"/home/redalexdad/anaconda3/envs/dl_science/lib/python3.9/site-packages/numba/__init__.py\", line 40, in _ensure_critical_deps\n    raise ImportError(msg)\nImportError: Numba needs NumPy 1.22 or greater. Got NumPy 1.20.\n"
     ]
    }
   ],
   "source": [
    "# Пример обучения модели на нескольких эпохах\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (waveform, transcription) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(waveform)\n",
    "        # Преобразование текстов в тензоры для расчета функции потерь CTC\n",
    "        target = torch.IntTensor([ord(char) for char in transcription])\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Эпоха {epoch+1}/{num_epochs}, Шаг {batch_idx}, Потеря: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2152b1-955b-40e5-8f6a-b755bd2a0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение обученной модели\n",
    "torch.save(model.state_dict(), \"my_model_001.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78233a-2a18-4008-bd6e-c744f756fa90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
